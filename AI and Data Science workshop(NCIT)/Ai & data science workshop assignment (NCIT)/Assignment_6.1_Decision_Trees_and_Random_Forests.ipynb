{"cells":[{"cell_type":"markdown","metadata":{"id":"i1OYH3aV_Cur"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Nepal-College-of-Information-Technology/AI-Data-Science-Worksop-2024/blob/main/Practice%20Yourself/Assignment_6.1_Decision_Trees_and_Random_Forests.ipynb)\n"]},{"cell_type":"markdown","metadata":{"id":"-lpTsWDK_Cuv"},"source":["# Assignment 6.1: Decision Trees and Random Forests\n","\n","## Objective:\n","Build and evaluate a **Decision Tree** and a **Random Forest** classifier to predict whether a bank customer will subscribe to a term deposit based on various customer attributes (such as age, job, marital status, etc.).\n","\n","### Dataset:\n","You can use the [Bank Marketing Dataset](https://archive.ics.uci.edu/ml/datasets/bank+marketing) or a similar dataset with customer attributes.\n","\n","---\n","\n","## Tasks:\n","\n","### Task 1: Load and Preprocess the Dataset\n","\n","1. Load the dataset into a Pandas DataFrame.\n","2. Handle any missing data if present.\n","3. Convert categorical variables to numerical values using one-hot encoding.\n"]},{"cell_type":"markdown","metadata":{"id":"UkUTOSlp_Cuv"},"source":["\n","```python\n","import pandas as pd\n","\n","# Load the dataset\n","df = pd.read_csv('your_dataset.csv')  # Replace with the actual dataset path\n","\n","# Handle missing data (if necessary)\n","# df.fillna(0, inplace=True)  # Example for handling missing values\n","\n","# One-hot encode categorical variables\n","df_encoded = pd.get_dummies(df, drop_first=True)\n","\n","# Display the first few rows of the preprocessed dataset\n","df_encoded.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"On5H6Ss0_Cuw"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","df = pd.read_csv('/content/bank.csv')\n","\n","df.fillna(0, inplace=True)\n","df_encoded = pd.get_dummies(df, drop_first=True)\n","\n","print(df_encoded.head())\n"]},{"cell_type":"markdown","metadata":{"id":"pft2_-oG_Cux"},"source":["### Task 2: Split the Dataset\n","\n","Split the dataset into training and testing sets using an 80-20 ratio."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"izkZv-l6_Cux"},"outputs":[],"source":["from sklearn.datasets import load_iris\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn import tree\n","import matplotlib.pyplot as plt\n","\n","iris = load_iris()\n","X = iris.data\n","y = iris.target\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"]},{"cell_type":"markdown","metadata":{"id":"bB83MyjQ_Cuy"},"source":["### Task 3: Train a Decision Tree Classifier\n","\n","1.\tTrain a Decision Tree Classifier on the training data.\n","2.\tVisualize the trained decision tree.\n","3.\tMake predictions on the test data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LuPCv1Za_Cuy"},"outputs":[],"source":["clf = DecisionTreeClassifier()\n","clf.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"WwLmLxvg_Cuy"},"source":["### Task 4: Train a Random Forest Classifier\n","\n","1.\tTrain a Random Forest Classifier on the training data.\n","2.\tCompare the performance of the Random Forest with the Decision Tree."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bJHVKkDr_Cuz"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","rf_classifier = RandomForestClassifier(random_state=42)\n","rf_classifier.fit(X_train, y_train)\n","\n","\n","y_pred_rf = rf_classifier.predict(X_test)\n","rf_accuracy = accuracy_score(y_test, y_pred_rf)\n","print(\"Random Forest Accuracy:\", rf_accuracy)\n","print(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n"]},{"cell_type":"markdown","metadata":{"id":"C_FKZr-z_Cuz"},"source":["### Task 5: Evaluate the Models\n","\n","Calculate and compare the accuracy, precision, recall, and F1-score for both the Decision Tree and Random Forest models."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lq1wUAp4_Cuz"},"outputs":[],"source":["\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","dt_model = DecisionTreeClassifier()\n","dt_model.fit(X_train, y_train)\n","\n","dt_predictions = dt_model.predict(X_test)\n","dt_accuracy = accuracy_score(y_test, dt_predictions)\n","dt_precision = precision_score(y_test, dt_predictions, average='weighted')\n","dt_recall = recall_score(y_test, dt_predictions, average='weighted')\n","dt_f1 = f1_score(y_test, dt_predictions, average='weighted')\n","rf_model = RandomForestClassifier()\n","rf_model.fit(X_train, y_train)\n","rf_predictions = rf_model.predict(X_test)\n","\n","\n","rf_accuracy = accuracy_score(y_test, rf_predictions)\n","rf_precision = precision_score(y_test, rf_predictions, average='weighted')\n","rf_recall = recall_score(y_test, rf_predictions, average='weighted')\n","rf_f1 = f1_score(y_test, rf_predictions, average='weighted')\n","\n","print(f\"Decision Tree - Accuracy: {dt_accuracy}, Precision: {dt_precision}, Recall: {dt_recall}, F1-score: {dt_f1}\")\n","print(f\"Random Forest - Accuracy: {rf_accuracy}, Precision: {rf_precision}, Recall: {rf_recall}, F1-score: {rf_f1}\")\n"]},{"cell_type":"markdown","metadata":{"id":"ZBzAClAT_Cuz"},"source":["### Task 6: Confusion Matrix\n","\n","1.\tGenerate the confusion matrix for both models.\n","2.\tVisualize the confusion matrix using a heatmap."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"66X0gvHr_Cuz"},"outputs":[],"source":["\n","y_true = [0, 6, 0, 1, 1, 0, 1, 9]\n","y_pred = [0, 1, 0, 1, 4, 0, 1, 1]\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","\n","cm = confusion_matrix(y_true, y_pred)\n","\n","\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', xticklabels=['Predicted Negative', 'Predicted Positive'], yticklabels=['Actual Negative', 'Actual Positive'])\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.title('Confusion Matrix')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"2wvvWVRr_Cu0"},"source":["### Conclusion:\n","\n","In this assignment, you:\n","\n","- Loaded and preprocessed the dataset.\n","- Trained a Decision Tree and a Random Forest classifier.\n","- Compared their performance using accuracy, precision, recall, and F1-score.\n","- Visualized their performance using confusion matrices.\n","\n","Which model performed better, and why?"]},{"cell_type":"markdown","metadata":{"id":"Dn5ZpILM_Cu0"},"source":["(write your answer here....)"]},{"cell_type":"markdown","metadata":{"id":"5A-lh8zo_Cu0"},"source":["---"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"provenance":[{"file_id":"https://github.com/Nepal-College-of-Information-Technology/AI-Data-Science-Worksop-2024/blob/main/Practice%20Yourself/Assignment_6.1_Decision_Trees_and_Random_Forests.ipynb","timestamp":1728220850188}]}},"nbformat":4,"nbformat_minor":0}